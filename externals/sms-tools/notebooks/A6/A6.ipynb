{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A6\n",
    "## Part1 - Estimate fundamental frequency in polyphonic audio signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.signal import get_window\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(os.path.join(os.path.dirname(os.path.realpath(__file__)), '../../software/models/'))\n",
    "import utilFunctions as UF\n",
    "import harmonicModel as HM\n",
    "import sineModel as SM\n",
    "import stft\n",
    "\n",
    "eps = np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the analysis parameters used within the function estimateF0() to obtain a good estimate of the \n",
    "fundamental frequency (`f0`) corresponding to one melody within a complex audio signal. The signal \n",
    "is a cello recording `cello-double-2.wav`, in which two strings are played simultaneously. One string \n",
    "plays a constant drone while the other string plays a simple melody. You have to choose the analysis \n",
    "parameter values such that only the `f0` frequency of the simple melody is tracked.\n",
    "\n",
    "The input argument to the function is the wav file name including the path (`inputFile`). The function \n",
    "returns a numpy array of the `f0` frequency values for each audio frame. For this question we take \n",
    "hopSize (`H`) = 256 samples. \n",
    "\n",
    "`estimateF0()` calls `f0Detection()` function of the `harmonicModel.py`, which uses the two way mismatch \n",
    "algorithm for `f0` estimation. \n",
    "\n",
    "`estimateF0()` also plots the `f0` contour on top of the spectrogram of the audio signal for you to \n",
    "visually analyse the performance of your chosen values for the analysis parameters. In this question \n",
    "we will only focus on the time segment between 0.5 and 4 seconds. So, your analysis parameter values \n",
    "should produce a good `f0` contour in this time region.\n",
    "\n",
    "In addition to plotting the `f0` contour on the spectrogram, this function also synthesizes the `f0` \n",
    "contour. You can also evaluate the performance of your chosen analysis parameter values by listening \n",
    "to this synthesized wav file named `'synthF0Contour.wav'`\n",
    "\n",
    "Since there can be numerous combinations of the optimal analysis parameter values, the evaluation is \n",
    "done solely on the basis of the output `f0` sequence. Note that only the segment of the `f0` contour \n",
    "between time 0.5 to 4 seconds is used to evaluate the performance of `f0` estimation.\n",
    "\n",
    "Your assignment will be tested only on inputFile = `'../../sounds/cello-double-2.wav'`. So choose the \n",
    "analysis parameters using which the function estimates the `f0` frequency contour corresponding to the \n",
    "string playing simple melody and not the drone. There is no separate test case for this question. \n",
    "You can keep working with the wav file mentioned above and when you think the performance is \n",
    "satisfactory you can submit the assignment. The plots can help you achieve a good performance. \n",
    "\n",
    "Be cautious while choosing the window size. Window size should be large enough to resolve the spectral \n",
    "peaks and small enough to preserve the note transitions. Very large window sizes may smear the `f0` \n",
    "contour at note transitions.\n",
    "\n",
    "Depending on the parameters you choose and the capabilities of the hardware you use, the function \n",
    "might take a while to run (even half a minute in some cases). For this part of the assignment please \n",
    "refrain from posting your analysis parameters on the discussion forum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateF0(inputFile = '../../sounds/cello-double-2.wav'):\n",
    "    \"\"\"\n",
    "    Function to estimate fundamental frequency (f0) in an audio signal. This function also plots the \n",
    "    f0 contour on the spectrogram and synthesize the f0 contour.\n",
    "    Input:\n",
    "        inputFile (string): wav file including the path\n",
    "    Output:\n",
    "        f0 (numpy array): array of the estimated fundamental frequency (f0) values\n",
    "    \"\"\"\n",
    "\n",
    "    ### Change these analysis parameter values marked as XX\n",
    "    window = XX\n",
    "    M = XX\n",
    "    N = XX\n",
    "    f0et = XX\n",
    "    t = XX\n",
    "    minf0 = XX\n",
    "    maxf0 = XX\n",
    "\n",
    "    ### Do not modify the code below \n",
    "    H = 256                                                     #fix hop size\n",
    "      \n",
    "    fs, x = UF.wavread(inputFile)                               #reading inputFile\n",
    "    w  = get_window(window, M)                                  #obtaining analysis window    \n",
    "    \n",
    "    ### Method 1\n",
    "    f0 = HM.f0Detection(x, fs, w, N, H, t, minf0, maxf0, f0et)  #estimating F0\n",
    "    startFrame = np.floor(0.5*fs/H)    \n",
    "    endFrame = np.ceil(4.0*fs/H)\n",
    "    f0[:startFrame] = 0\n",
    "    f0[endFrame:] = 0\n",
    "    y = UF.sinewaveSynth(f0, 0.8, H, fs)\n",
    "    UF.wavwrite(y, fs, 'synthF0Contour.wav')\n",
    "\n",
    "    ## Code for plotting the f0 contour on top of the spectrogram\n",
    "    # frequency range to plot\n",
    "    maxplotfreq = 500.0    \n",
    "    fontSize = 16\n",
    "    plot = 1\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    mX, pX = stft.stftAnal(x, w, N, H)                      #using same params as used for analysis\n",
    "    mX = np.transpose(mX[:,:int(N*(maxplotfreq/fs))+1])\n",
    "    \n",
    "    timeStamps = np.arange(mX.shape[1])*H/float(fs)                             \n",
    "    binFreqs = np.arange(mX.shape[0])*fs/float(N)\n",
    "    \n",
    "    plt.pcolormesh(timeStamps, binFreqs, mX)\n",
    "    plt.plot(timeStamps, f0, color = 'k', linewidth=1.5)\n",
    "    plt.plot([0.5, 0.5], [0, maxplotfreq], color = 'b', linewidth=1.5)\n",
    "    plt.plot([4.0, 4.0], [0, maxplotfreq], color = 'b', linewidth=1.5)\n",
    "    \n",
    "    \n",
    "    plt.autoscale(tight=True)\n",
    "    plt.ylabel('Frequency (Hz)', fontsize = fontSize)\n",
    "    plt.xlabel('Time (s)', fontsize = fontSize)\n",
    "    plt.legend(('f0',))\n",
    "    \n",
    "    xLim = ax.get_xlim()\n",
    "    yLim = ax.get_ylim()\n",
    "    ax.set_aspect((xLim[1]-xLim[0])/(2.0*(yLim[1]-yLim[0])))    \n",
    "\n",
    "    if plot == 1: #save the plot too!\n",
    "        plt.autoscale(tight=True) \n",
    "        plt.show()\n",
    "    else:\n",
    "        fig.tight_layout()\n",
    "        fig.savefig('f0_over_Spectrogram.png', dpi=150, bbox_inches='tight')\n",
    "\n",
    "    return f0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Segmentation of stable note regions in an audio signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the function `segmentStableNotesRegions()` to identify the stable regions of notes in a specific \n",
    "monophonic audio signal. The function returns an array of segments where each segment contains the \n",
    "starting and the ending frame index of a stable note.\n",
    "\n",
    "The input argument to the function are the wav file name including the path (`inputFile`), threshold to \n",
    "be used for deciding stable notes (`stdThsld`) in cents, minimum allowed duration of a stable note (`minNoteDur`), \n",
    "number of samples to be considered for computing standard deviation (`winStable`), analysis window (`window`), \n",
    "window size (`M`), FFT size (`N`), hop size (`H`), error threshold used in the f0 detection (`f0et`), magnitude \n",
    "threshold for spectral peak picking (`t`), minimum allowed f0 (`minf0`) and maximum allowed f0 (`maxf0`). \n",
    "The function returns a numpy array of `shape (k,2)`, where `k` is the total number of detected segments. \n",
    "The two columns in each row contains the starting and the ending frame indexes of a stable note segment. \n",
    "The segments must be returned in the increasing order of their start times. \n",
    "\n",
    "In order to facilitate the assignment we have configured the input parameters to work with a particular \n",
    "sound, `'../../sounds/sax-phrase-short.wav'`. The code and parameters to estimate the fundamental frequency \n",
    "is completed. Thus you start from an `f0` curve obtained using the `f0Detection()` function and you will use \n",
    "that to obtain the note segments. \n",
    "\n",
    "All the steps to be implemented in order to solve this question are indicated in `segmentStableNotesRegions()` \n",
    "as comments. These are the steps:\n",
    "\n",
    "1. In order to make the processing musically relevant, the `f0` values should be converted first from Hertz to Cents, which is a logarithmic scale. \n",
    "\n",
    "2. At each time frame (for each `f0` value) you should compute the standard deviation of the past `winStable` number of `f0` samples (including the `f0` sample at the current audio frame). \n",
    "\n",
    "3. You should then apply a deviation threshold, `stdThsld`, to determine if the current frame belongs to a stable note region or not. Since we are interested in the stable note regions, the standard deviation of the previous `winStable` number of `f0` samples (including the current sample) should be less than `stdThsld` i.e. use the current sample and `winStable-1` previous samples. Ignore the first `winStable-1` samples in this computation.\n",
    "\n",
    "4. All the consecutive frames belonging to the stable note regions should be grouped together into segments. For example, if the indexes of the frames corresponding to the stable note regions are 3,4,5,6,12,13,14, we get two segments, first 3-6 and second 12-14. \n",
    "\n",
    "5. After grouping frame indexes into segments filter/remove the segments which are smaller in duration than `minNoteDur`. Return the segment indexes in the increasing order of their start frame index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentStableNotesRegions(inputFile = '../../sounds/sax-phrase-short.wav', stdThsld=10, minNoteDur=0.1, \n",
    "                              winStable = 3, window='hamming', M=1024, N=2048, H=256, f0et=5.0, t=-100, \n",
    "                              minf0=310, maxf0=650):\n",
    "    \"\"\"\n",
    "    Function to segment the stable note regions in an audio signal\n",
    "    Input:\n",
    "        inputFile (string): wav file including the path\n",
    "        stdThsld (float): threshold for detecting stable regions in the f0 contour (in cents)\n",
    "        minNoteDur (float): minimum allowed segment length (note duration)  \n",
    "        winStable (integer): number of samples used for computing standard deviation\n",
    "        window (string): analysis window\n",
    "        M (integer): window size used for computing f0 contour\n",
    "        N (integer): FFT size used for computing f0 contour\n",
    "        H (integer): Hop size used for computing f0 contour\n",
    "        f0et (float): error threshold used for the f0 computation\n",
    "        t (float): magnitude threshold in dB used in spectral peak picking\n",
    "        minf0 (float): minimum fundamental frequency in Hz\n",
    "        maxf0 (float): maximum fundamental frequency in Hz\n",
    "    Output:\n",
    "        segments (np.ndarray): Numpy array containing starting and ending frame indexes of every segment.\n",
    "    \"\"\"\n",
    "    fs, x = UF.wavread(inputFile)                               #reading inputFile\n",
    "    w  = get_window(window, M)                                  #obtaining analysis window    \n",
    "    f0 = HM.f0Detection(x, fs, w, N, H, t, minf0, maxf0, f0et)  #estimating F0\n",
    "\n",
    "    ### your code here\n",
    "\n",
    "    # 1. convert f0 values from Hz to Cents (as described in pdf document)\n",
    "\n",
    "    #2. create an array containing standard deviation of last winStable samples\n",
    "\n",
    "    #3. apply threshold on standard deviation values to find indexes of the stable points in melody\n",
    "\n",
    "    #4. create segments of continuous stable points such that consecutive stable points belong to same segment\n",
    "    \n",
    "    #5. apply segment filtering, i.e. remove segments with are < minNoteDur in length\n",
    "    \n",
    "    # plotSpectogramF0Segments(x, fs, w, N, H, f0, segments)  # Plot spectrogram and F0 if needed\n",
    "\n",
    "    # return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSpectogramF0Segments(x, fs, w, N, H, f0, segments):\n",
    "    \"\"\"\n",
    "    Code for plotting the f0 contour on top of the spectrogram\n",
    "    \"\"\"\n",
    "    # frequency range to plot\n",
    "    maxplotfreq = 1000.0    \n",
    "    fontSize = 16\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    mX, pX = stft.stftAnal(x, w, N, H)                      #using same params as used for analysis\n",
    "    mX = np.transpose(mX[:,:int(N*(maxplotfreq/fs))+1])\n",
    "    \n",
    "    timeStamps = np.arange(mX.shape[1])*H/float(fs)                             \n",
    "    binFreqs = np.arange(mX.shape[0])*fs/float(N)\n",
    "    \n",
    "    plt.pcolormesh(timeStamps, binFreqs, mX)\n",
    "    plt.plot(timeStamps, f0, color = 'k', linewidth=5)\n",
    "\n",
    "    for ii in range(segments.shape[0]):\n",
    "        plt.plot(timeStamps[segments[ii,0]:segments[ii,1]], f0[segments[ii,0]:segments[ii,1]], color = '#A9E2F3', linewidth=1.5)        \n",
    "    \n",
    "    plt.autoscale(tight=True)\n",
    "    plt.ylabel('Frequency (Hz)', fontsize = fontSize)\n",
    "    plt.xlabel('Time (s)', fontsize = fontSize)\n",
    "    plt.legend(('f0','segments'))\n",
    "    \n",
    "    xLim = ax.get_xlim()\n",
    "    yLim = ax.get_ylim()\n",
    "    ax.set_aspect((xLim[1]-xLim[0])/(2.0*(yLim[1]-yLim[0])))    \n",
    "    plt.autoscale(tight=True) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test case 1: Using `inputFile='../../sounds/cello-phrase.wav', stdThsld=10, minNoteDur=0.1, \n",
    "winStable = 3, window='hamming', M=1025, N=2048, H=256, f0et=5.0, t=-100, minf0=310, maxf0=650`, \n",
    "the function `segmentStableNotesRegions()` should return 9 segments. \n",
    "\n",
    "Please use `loadTestcases.load()` \n",
    "to check the expected segment indexes in the output.\n",
    "\n",
    "Test case 2: Using `inputFile='../../sounds/cello-phrase.wav', stdThsld=20, minNoteDur=0.5, \n",
    "winStable = 3, window='hamming', M=1025, N=2048, H=256, f0et=5.0, t=-100, minf0=310, maxf0=650`, \n",
    "the function `segmentStableNotesRegions()` should return 6 segments. Please use loadTestcases.load() \n",
    "to check the expected segment indexes in the output.\n",
    "\n",
    "Test case 3: Using `inputFile='../../sounds/sax-phrase-short.wav', stdThsld=5, minNoteDur=0.6, \n",
    "winStable = 3, window='hamming', M=1025, N=2048, H=256, f0et=5.0, t=-100, minf0=310, maxf0=650`, \n",
    "the function `segmentStableNotesRegions()` should return just one segment. Please use `loadTestcases.load()` \n",
    "to check the expected segment indexes in the output. \n",
    "\n",
    "We also provide the function `plotSpectogramF0Segments()` to plot the `f0` contour and the detected \n",
    "segments on the top of the spectrogram of the audio signal in order to visually analyse the outcome \n",
    "of your function. Depending on the analysis parameters and the capabilities of the hardware you \n",
    "use, the function might take a while to run (even half a minute in some cases). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your plots here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Compute amount of inharmonicity present in a sound\n",
    "\n",
    "Write a function that measures the amount of inharmonicity present in a pitched/harmonic sound. The \n",
    "function should measure the mean inharmonicity in the sound over the time interval `t1` to `t2`.\n",
    "\n",
    "The input argument to the function are the wav file name including the path (`inputFile`), start (`t1`) \n",
    "and end time (`t2`) of the audio segment to compute inharmonicity, analysis window (`window`), window \n",
    "size (`M`), FFT size (`N`), hop size (`H`), error threshold used in the `f0` detection (`f0et`), magnitude \n",
    "threshold for spectral peak picking (`t`), minimum allowed f0 (`minf0`), maximum allowed f0 (`maxf0`) and \n",
    "number of harmonics to be considered in the computation of inharmonicity (`nH`). The function returns \n",
    "a single numpy float, which is the mean inharmonicity over time `t1` to `t2`. \n",
    "\n",
    "A brief description of the method to compute inharmonicity is provided in the Relevant Concepts \n",
    "section of the assignment pdf. The steps to be done are:\n",
    "\n",
    "1. Use `harmonicModelAnal` function in harmonicModel module for computing the harmonic frequencies and their magnitudes at each audio frame. The first harmonic is the fundamental frequency. For `harmonicModelAnal` use `harmDevSlope=0.01`, `minSineDur=0.0`. Use `harmonicModelAnal` to estimate harmonic frequencies and magnitudes for the entire audio signal.\n",
    "\n",
    "2. For the computation of the inharmonicity choose the frames that are between the time interval `t1` and `t2`. Do not slice the audio signal between the time interval `t1` and `t2` before estimating harmonic frequencies. \n",
    "\n",
    "3. Use the formula given in the Relevant Concepts section to compute the inharmonicity measure for the given interval. Note that for some frames some of the harmonics might not be detected due to their low energy. For handling such cases use only the detected harmonics (and set the value of `R` in the equation to the number of detected hamonics) to compute the inharmonicity measure. All the detected harmonics have a non-zero frequency.\n",
    "\n",
    "In this question we will work with a piano sound (`'../../sounds/piano.wav'`), a typical example of an \n",
    "instrument that exhibits inharmonicity \n",
    "(http://en.wikipedia.org/wiki/Piano_acoustics#Inharmonicity_and_piano_size). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateInharmonicity(inputFile = '../../sounds/piano.wav', t1=0.1, t2=0.5, window='hamming', \n",
    "                            M=2048, N=2048, H=128, f0et=5.0, t=-90, minf0=130, maxf0=180, nH = 10):\n",
    "    \"\"\"\n",
    "    Function to estimate the extent of inharmonicity present in a sound\n",
    "    Input:\n",
    "        inputFile (string): wav file including the path\n",
    "        t1 (float): start time of the segment considered for computing inharmonicity\n",
    "        t2 (float): end time of the segment considered for computing inharmonicity\n",
    "        window (string): analysis window\n",
    "        M (integer): window size used for computing f0 contour\n",
    "        N (integer): FFT size used for computing f0 contour\n",
    "        H (integer): Hop size used for computing f0 contour\n",
    "        f0et (float): error threshold used for the f0 computation\n",
    "        t (float): magnitude threshold in dB used in spectral peak picking\n",
    "        minf0 (float): minimum fundamental frequency in Hz\n",
    "        maxf0 (float): maximum fundamental frequency in Hz\n",
    "        nH (integer): number of integers considered for computing inharmonicity\n",
    "    Output:\n",
    "        meanInharm (float or np.float): mean inharmonicity over all the frames between the time interval \n",
    "                                        t1 and t2. \n",
    "    \"\"\"\n",
    "    # 0. Read the audio file and obtain an analysis window\n",
    "    \n",
    "    # 1. Use harmonic model to compute the harmonic frequencies and magnitudes\n",
    "    \n",
    "    # 2. Extract the time segment in which you need to compute the inharmonicity. \n",
    "    \n",
    "    # 3. Compute the mean inharmonicity of the segment\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test case 1: If you run your code with `inputFile = '../../sounds/piano.wav', t1=0.2, t2=0.4, window='hamming', M=2047, N=2048, H=128, f0et=5.0, t=-90, minf0=130, maxf0=180, nH = 25`, the returned output should be `1.4543`. \n",
    "\n",
    "Test case 2: If you run your code with `inputFile = '../../sounds/piano.wav', t1=2.3, t2=2.55, window='hamming', M=2047, N=2048, H=128, f0et=5.0, t=-90, minf0=230, maxf0=290, nH = 15`, the returned output should be `1.4874`. \n",
    "\n",
    "Test case 3: If you run your code with `inputFile = '../../sounds/piano.wav', t1=2.55, t2=2.8, window='hamming', M=2047, N=2048, H=128, f0et=5.0, t=-90, minf0=230, maxf0=290, nH = 5`, the returned output should be `0.1748`. \n",
    "\n",
    "Optional/Additional tasks\n",
    "An interesting task would be to compare the inharmonicities present in the sounds of different instruments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Improving the implementation of the two way mismatch f0 estimation algorithm\n",
    "\n",
    "Improve the performance of the current implementation of the two way mismatch algorithm in sms-tools \n",
    "used for fundamental frequency estimation. This is an optional open question and will not contribute \n",
    "towards the final grade. There is no definite answer for this question. Its main purpose is to \n",
    "understand the limitations of the current implementations of the TWM algorithm and to come up with \n",
    "some community driven solutions based on collective thinking. \n",
    "\n",
    "In this question you will directly modify the core functions that implement the TWM algorithm in \n",
    "sms-tools. To assist you with this task, we have copied all the needed functions into this python \n",
    "file. Hence, you just need to modify the functions in this file and not anywhere else.\n",
    "\n",
    "Estimating fundamental frequency from an audio signal is still a challenging and unsolved problem \n",
    "to a large extent. By this time you might have also realized that many times the performance of the \n",
    "TWM `f0` estimation algorithm falls short of the expectations. There can be a systematic explanation \n",
    "for the scenarios where TWM fails for specific categories or characteristics of the sounds. Some of \n",
    "the known scenarios where the current implementation of the TWM algorithm fails to estimate a correct \n",
    "fundamental frequency are:\n",
    "\n",
    "1) Missing fundamental frequency: For many sounds the fundamental frequency component is very low and therefore during the spectral peak picking step we do not obtain any peak corresponding to the `f0`. Since the TWM algorithm implemented in sms-tools considers only the detected spectral peaks as the `f0` candidates, we do not get any candidate corresponding to the `f0`. This causes `f0` estimation to fail. For example, such a scenario is encountered in low pitched vocal sounds.\n",
    "\n",
    "2) Pseudo-harmonicity in the sound. Many instruments such as piano exhibit some deviation from perfect harmonicity wherein their harmonic partials are not perfectly located at integral multiples of the fundamental frequency. Since the TWM algorithm computes error function assuming that the harmonic locations are at integral multiples, its performance is poorer when such deviations exist.\n",
    "\n",
    "In this question we propose to work on these two scenarios. Go to freesound and download sound examples \n",
    "of low pitched vocal sounds and of piano. Run current implementation of TMW to identify the limitations \n",
    "and propose improvements to the code in order to obtain better `f0` estimation for those two particular \n",
    "scenarios. \n",
    "\n",
    "The core TWM algorithm is implemented in the function `TWM_p()`, which takes in an array of `f0` candidates \n",
    "and detect the candidate that has the lowest error. `TWM_p()` is called by `f0Twm()`, which generates \n",
    "`f0` candidates `(f0c = np.argwhere((pfreq>minf0) & (pfreq<maxf0))[:,0])`. This function also implements \n",
    "a memory based prunning of the `f0` candidates. If the `f0` contour is found to be stable (no drastic \n",
    "transitions across frames) then only the `f0` candidates close to the stable `f0` value are retained. \n",
    "`f0Twm()` is called for every audio frame by `f0Detection()`.\n",
    "\n",
    "You can use `computeAndPlotF0()`, which calls `f0Detection()` for estimating `f0` for every audio frame. \n",
    "In addition, it also plots the `f0` contour on the top of the spectrogram. If you set `plot=1`, it shows \n",
    "the plot, `plot=2` saves the plot as can be seen in the code. \n",
    "\n",
    "Once you implement your proposed enhancement, discuss and share your ideas on the discussion forum \n",
    "assigned for A6Part4 - https://class.coursera.org/audio-001/forum/list?forum_id=10026. Along with the \n",
    "text you should include 2 plots showing the `f0` contour before and after your changes. Use the same \n",
    "values of the analysis parameters while showing the improvement in the performance. in the discussion, \n",
    "also include a link to the sound in freesound. \n",
    "\n",
    "TIP: An identified limitation of the current implementation for the case of low vocal sounds is that \n",
    "it can only find `f0` if there is a peak present in the magnitude spectrum. A possible improvement is \n",
    "to generate additional `f0` candidates from the identified peaks. Another identified limitation for \n",
    "the case of piano sounds is the assumption of perfect harmonicity. For these sounds you can think \n",
    "of modifying the generation of the ideal harmonic series that is computed in the code, incorporating \n",
    "the typical deviation from harmonicity encountered in piano sounds.\n",
    "\n",
    "NOTE: Before you start making changes in the TWM implementation make sure you have reached the best \n",
    "possible performance that can be achieved by tuning the analysis parameters. If the analysis parameters \n",
    "are inappropriately set, it is not completely meaningful to just improve the TWM implementation.\n",
    "\n",
    "To maintain the integrity if the sms-tools package for future assignments, please make changes only \n",
    "to the functions in this file and not the other files in sms-tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAndPlotF0(inputFile = '../../sounds/piano.wav'):\n",
    "    \"\"\"\n",
    "    Function to estimate fundamental frequency (f0) in an audio signal using TWM.\n",
    "    Input:\n",
    "        inputFile (string): wav file including the path    \n",
    "    \"\"\"\n",
    "    window='hamming'\n",
    "    M=2048\n",
    "    N=2048\n",
    "    H=256\n",
    "    f0et=5.0\n",
    "    t=-80\n",
    "    minf0=100\n",
    "    maxf0=300\n",
    "\n",
    "    fs, x = UF.wavread(inputFile)                               #reading inputFile\n",
    "    w  = get_window(window, M)                                  #obtaining analysis window    \n",
    "    f0 = f0Detection(x, fs, w, N, H, t, minf0, maxf0, f0et)  #estimating F0\n",
    "\n",
    "    ## Code for plotting the f0 contour on top of the spectrogram\n",
    "    # frequency range to plot\n",
    "    maxplotfreq = 500.0    \n",
    "    fontSize = 16\n",
    "    plot = 1\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    mX, pX = stft.stftAnal(x, w, N, H)                      #using same params as used for analysis\n",
    "    mX = np.transpose(mX[:,:int(N*(maxplotfreq/fs))+1])\n",
    "    \n",
    "    timeStamps = np.arange(mX.shape[1])*H/float(fs)                             \n",
    "    binFreqs = np.arange(mX.shape[0])*fs/float(N)\n",
    "    \n",
    "    plt.pcolormesh(timeStamps, binFreqs, mX)\n",
    "    plt.plot(timeStamps, f0, color = 'k', linewidth=1.5)\n",
    "    \n",
    "    plt.autoscale(tight=True)\n",
    "    plt.ylabel('Frequency (Hz)', fontsize = fontSize)\n",
    "    plt.xlabel('Time (s)', fontsize = fontSize)\n",
    "    plt.legend(('f0',))\n",
    "    \n",
    "    xLim = ax.get_xlim()\n",
    "    yLim = ax.get_ylim()\n",
    "    ax.set_aspect((xLim[1]-xLim[0])/(2.0*(yLim[1]-yLim[0])))    \n",
    "\n",
    "    if plot == 1: \n",
    "        plt.autoscale(tight=True) \n",
    "        plt.show()\n",
    "    elif plot == 2:                   #you can save the plot too!\n",
    "        fig.tight_layout()\n",
    "        fig.savefig('f0_over_Spectrogram.png', dpi=150, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f0Detection(x, fs, w, N, H, t, minf0, maxf0, f0et):\n",
    "    \"\"\"\n",
    "    Fundamental frequency detection of a sound using twm algorithm\n",
    "    x: input sound; fs: sampling rate; w: analysis window; \n",
    "    N: FFT size; t: threshold in negative dB, \n",
    "    minf0: minimum f0 frequency in Hz, maxf0: maximim f0 frequency in Hz, \n",
    "    f0et: error threshold in the f0 detection (ex: 5),\n",
    "    returns f0: fundamental frequency\n",
    "    \"\"\"\n",
    "    if (minf0 < 0):                                            # raise exception if minf0 is smaller than 0\n",
    "        raise ValueError(\"Minumum fundamental frequency (minf0) smaller than 0\")\n",
    "    \n",
    "    if (maxf0 >= 10000):                                       # raise exception if maxf0 is bigger than fs/2\n",
    "        raise ValueError(\"Maximum fundamental frequency (maxf0) bigger than 10000Hz\")\n",
    "    \n",
    "    if (H <= 0):                                               # raise error if hop size 0 or negative\n",
    "        raise ValueError(\"Hop size (H) smaller or equal to 0\")\n",
    "        \n",
    "    hN = N/2                                                   # size of positive spectrum\n",
    "    hM1 = int(math.floor((w.size+1)/2))                        # half analysis window size by rounding\n",
    "    hM2 = int(math.floor(w.size/2))                            # half analysis window size by floor\n",
    "    x = np.append(np.zeros(hM2),x)                             # add zeros at beginning to center first window at sample 0\n",
    "    x = np.append(x,np.zeros(hM1))                             # add zeros at the end to analyze last sample\n",
    "    pin = hM1                                                  # init sound pointer in middle of anal window          \n",
    "    pend = x.size - hM1                                        # last sample to start a frame\n",
    "    fftbuffer = np.zeros(N)                                    # initialize buffer for FFT\n",
    "    w = w / sum(w)                                             # normalize analysis window\n",
    "    f0 = []                                                    # initialize f0 output\n",
    "    f0t = 0                                                    # initialize f0 track\n",
    "    f0stable = 0                                               # initialize f0 stable\n",
    "    while pin<pend:             \n",
    "        x1 = x[pin-hM1:pin+hM2]                                  # select frame\n",
    "        mX, pX = DFT.dftAnal(x1, w, N)                           # compute dft           \n",
    "        ploc = UF.peakDetection(mX, t)                           # detect peak locations   \n",
    "        iploc, ipmag, ipphase = UF.peakInterp(mX, pX, ploc)      # refine peak values\n",
    "        ipfreq = fs * iploc/N                                    # convert locations to Hez\n",
    "        f0t = f0Twm(ipfreq, ipmag, f0et, minf0, maxf0, f0stable)  # find f0\n",
    "        if ((f0stable==0)&(f0t>0)) \\\n",
    "                or ((f0stable>0)&(np.abs(f0stable-f0t)<f0stable/5.0)):\n",
    "            f0stable = f0t                                         # consider a stable f0 if it is close to the previous one\n",
    "        else:\n",
    "            f0stable = 0\n",
    "        f0 = np.append(f0, f0t)                                  # add f0 to output array\n",
    "        pin += H                                                 # advance sound pointer\n",
    "    return f0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f0Twm(pfreq, pmag, ef0max, minf0, maxf0, f0t=0):\n",
    "    \"\"\"\n",
    "    Function that wraps the f0 detection function TWM, selecting the possible f0 candidates\n",
    "    and calling the function TWM with them\n",
    "    pfreq, pmag: peak frequencies and magnitudes, \n",
    "    ef0max: maximum error allowed, minf0, maxf0: minimum  and maximum f0\n",
    "    f0t: f0 of previous frame if stable\n",
    "    returns f0: fundamental frequency in Hz\n",
    "    \"\"\"\n",
    "    if (minf0 < 0):                                  # raise exception if minf0 is smaller than 0\n",
    "        raise ValueError(\"Minumum fundamental frequency (minf0) smaller than 0\")\n",
    "    \n",
    "    if (maxf0 >= 10000):                             # raise exception if maxf0 is bigger than 10000Hz\n",
    "        raise ValueError(\"Maximum fundamental frequency (maxf0) bigger than 10000Hz\")\n",
    "        \n",
    "    if (pfreq.size < 3) & (f0t == 0):                # return 0 if less than 3 peaks and not previous f0\n",
    "        return 0\n",
    "    \n",
    "    f0c = np.argwhere((pfreq>minf0) & (pfreq<maxf0))[:,0] # use only peaks within given range\n",
    "    if (f0c.size == 0):                              # return 0 if no peaks within range\n",
    "        return 0\n",
    "    f0cf = pfreq[f0c]                                # frequencies of peak candidates\n",
    "    f0cm = pmag[f0c]                                 # magnitude of peak candidates\n",
    "\n",
    "    if f0t>0:                                        # if stable f0 in previous frame \n",
    "        shortlist = np.argwhere(np.abs(f0cf-f0t)<f0t/2.0)[:,0]   # use only peaks close to it\n",
    "        maxc = np.argmax(f0cm)\n",
    "        maxcfd = f0cf[maxc]%f0t\n",
    "        if maxcfd > f0t/2:\n",
    "            maxcfd = f0t - maxcfd\n",
    "        if (maxc not in shortlist) and (maxcfd>(f0t/4)): # or the maximum magnitude peak is not a harmonic\n",
    "            shortlist = np.append(maxc, shortlist)\n",
    "        f0cf = f0cf[shortlist]                         # frequencies of candidates                     \n",
    "\n",
    "    if (f0cf.size == 0):                             # return 0 if no peak candidates\n",
    "        return 0\n",
    "\n",
    "    f0, f0error = TWM_p(pfreq, pmag, f0cf)        # call the TWM function with peak candidates\n",
    "    \n",
    "    if (f0>0) and (f0error<ef0max):                  # accept and return f0 if below max error allowed\n",
    "        return f0\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TWM_p(pfreq, pmag, f0c):\n",
    "    \"\"\"\n",
    "    Two-way mismatch algorithm for f0 detection (by Beauchamp&Maher)\n",
    "    [better to use the C version of this function: UF_C.twm]\n",
    "    pfreq, pmag: peak frequencies in Hz and magnitudes, \n",
    "    f0c: frequencies of f0 candidates\n",
    "    returns f0, f0Error: fundamental frequency detected and its error\n",
    "    \"\"\"\n",
    "\n",
    "    p = 0.5                                          # weighting by frequency value\n",
    "    q = 1.4                                          # weighting related to magnitude of peaks\n",
    "    r = 0.5                                          # scaling related to magnitude of peaks\n",
    "    rho = 0.33                                       # weighting of MP error\n",
    "    Amax = max(pmag)                                 # maximum peak magnitude\n",
    "    maxnpeaks = 10                                   # maximum number of peaks used\n",
    "    harmonic = np.matrix(f0c)\n",
    "    ErrorPM = np.zeros(harmonic.size)                # initialize PM errors\n",
    "    MaxNPM = min(maxnpeaks, pfreq.size)\n",
    "    for i in range(0, MaxNPM) :                      # predicted to measured mismatch error\n",
    "        difmatrixPM = harmonic.T * np.ones(pfreq.size)\n",
    "        difmatrixPM = abs(difmatrixPM - np.ones((harmonic.size, 1))*pfreq)\n",
    "        FreqDistance = np.amin(difmatrixPM, axis=1)    # minimum along rows\n",
    "        peakloc = np.argmin(difmatrixPM, axis=1)\n",
    "        Ponddif = np.array(FreqDistance) * (np.array(harmonic.T)**(-p))\n",
    "        PeakMag = pmag[peakloc]\n",
    "        MagFactor = 10**((PeakMag-Amax)/20)\n",
    "        ErrorPM = ErrorPM + (Ponddif + MagFactor*(q*Ponddif-r)).T\n",
    "        harmonic = harmonic+f0c\n",
    "\n",
    "    ErrorMP = np.zeros(harmonic.size)                # initialize MP errors\n",
    "    MaxNMP = min(maxnpeaks, pfreq.size)\n",
    "    for i in range(0, f0c.size) :                    # measured to predicted mismatch error\n",
    "        nharm = np.round(pfreq[:MaxNMP]/f0c[i])\n",
    "        nharm = (nharm>=1)*nharm + (nharm<1)\n",
    "        FreqDistance = abs(pfreq[:MaxNMP] - nharm*f0c[i])\n",
    "        Ponddif = FreqDistance * (pfreq[:MaxNMP]**(-p))\n",
    "        PeakMag = pmag[:MaxNMP]\n",
    "        MagFactor = 10**((PeakMag-Amax)/20)\n",
    "        ErrorMP[i] = sum(MagFactor * (Ponddif + MagFactor*(q*Ponddif-r)))\n",
    "\n",
    "    Error = (ErrorPM[0]/MaxNPM) + (rho*ErrorMP/MaxNMP)  # total error\n",
    "    f0index = np.argmin(Error)                       # get the smallest error\n",
    "    f0 = f0c[f0index]                                # f0 with the smallest error\n",
    "\n",
    "    return f0, Error[f0index]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your plots here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
